{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfcadbed-a6eb-4c2a-863f-f90c001bf546",
   "metadata": {},
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33149d42-6363-4044-bf0c-058a4a383fc4",
   "metadata": {},
   "source": [
    "Manhattan distance captures the distance between two points by aggregating the pairwise absolute difference between each variable while Euclidean distance captures the same by aggregating the squared difference in each variable.We don't use Manhattan Distance, because it calculates distance horizontally or vertically only. It has dimension restrictions. On the other hand, the Euclidean metric can be used in any space to calculate distance. Since the data points can be represented in any dimension, it is a more viable option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c02b9-fca7-4500-9d0a-396f67fd2e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2793c486-2fbd-47f2-a4cf-bb0997026892",
   "metadata": {},
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33013a3-df3d-46a5-bc18-bc877b68c84f",
   "metadata": {},
   "source": [
    "The optimal K value usually found is the square root of N, where N is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value. KNN performs well with multi-label classes, but you must be aware of the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60760e-9b12-43a3-8273-6833f6b50eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5872185-bcfb-491e-8b22-7f6943b29bf9",
   "metadata": {},
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1e16e-b802-43f9-94c3-fdd95f4f3176",
   "metadata": {},
   "source": [
    "We mean by the 'best distance metric' (in this review) is the one that allows the KNN to classify test examples with the highest precision, recall and accuracy, i.e. the one that gives best performance of the KNN in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c008fb8-3a81-44c1-9ba2-bc898a93e54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72156580-d814-47dc-b4eb-d76c11d4c8a1",
   "metadata": {},
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ccf23-8de7-41cb-a643-6e410706ecc6",
   "metadata": {},
   "source": [
    "The most important hyperparameter for KNN is the number of neighbors (n_neighbors).    \n",
    "metric in [‘euclidean’, ‘manhattan’, ‘minkowski’]    \n",
    "weights in [‘uniform’, ‘distance’] \n",
    "We can use GridSearchCV to use hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882efbc5-643f-414d-958b-d4cfbc01137b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b8d5fad-9f00-4ee3-9c33-c2576c38d059",
   "metadata": {},
   "source": [
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085ba52-4c52-4997-9829-58996fab07aa",
   "metadata": {},
   "source": [
    "So if dataset is large, there will be a lot of processing which may adversely impact the performance of the algorithm. KNN is also very sensitive to noise in the dataset. If the dataset is large, there are chances of noise in the dataset which adversely affect the performance of KNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1898cf-1d81-4923-8920-cf9c20fd4cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e213a75-20ab-460d-861f-4a8786c7a737",
   "metadata": {},
   "source": [
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d190b0b-a55f-405d-9a1f-13bfb9302e7c",
   "metadata": {},
   "source": [
    "Limitations of KNN:         \n",
    "KNN is a very powerful algorithm. It is also called “lazy learner”. However, it has the following set of limitations:             \n",
    "\n",
    "1. Doesn’t work well with a large dataset:          \n",
    "Since KNN is a distance-based algorithm, the cost of calculating distance between a new point and each existing point is very high which in turn degrades the performance of the algorithm.         \n",
    "\n",
    "2. Doesn’t work well with a high number of dimensions:\n",
    "Again, the same reason as above. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance.\n",
    "\n",
    "3. Sensitive to outliers and missing values:\n",
    "KNN is sensitive to outliers and missing values and hence we first need to impute the missing values and get rid of the outliers before applying the KNN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5eb86d-e15c-4919-bf71-b882bbf8f517",
   "metadata": {},
   "source": [
    "KNN is sensitive to outliers and missing values and hence we first need to impute the missing values and get rid of the outliers before applying the KNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff80a8-47c9-4925-b402-1117c9afb7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
